{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_abpZ4kXvwCZ",
        "outputId": "c37a1873-1732-481b-8170-9f13e0ea9847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 336418734080.0000 - mae: 515526.4375 - val_loss: 613063458816.0000 - val_mae: 663163.2500\n",
            "Epoch 2/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 354760163328.0000 - mae: 535691.8125 - val_loss: 613062803456.0000 - val_mae: 663162.7500\n",
            "Epoch 3/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 336916709376.0000 - mae: 523669.5000 - val_loss: 613061754880.0000 - val_mae: 663161.9375\n",
            "Epoch 4/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 329579331584.0000 - mae: 526589.9375 - val_loss: 613060313088.0000 - val_mae: 663160.8125\n",
            "Epoch 5/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 333180239872.0000 - mae: 519080.6250 - val_loss: 613058084864.0000 - val_mae: 663159.2500\n",
            "Epoch 6/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 320607748096.0000 - mae: 514609.6562 - val_loss: 613054939136.0000 - val_mae: 663156.8750\n",
            "Epoch 7/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 344948473856.0000 - mae: 532678.4375 - val_loss: 613050679296.0000 - val_mae: 663153.6875\n",
            "Epoch 8/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 295034552320.0000 - mae: 499029.2188 - val_loss: 613045108736.0000 - val_mae: 663149.4375\n",
            "Epoch 9/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 350122311680.0000 - mae: 530702.3750 - val_loss: 613037506560.0000 - val_mae: 663143.8125\n",
            "Epoch 10/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 324003921920.0000 - mae: 518106.7812 - val_loss: 613027872768.0000 - val_mae: 663136.7500\n",
            "Epoch 11/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 282861043712.0000 - mae: 483533.2188 - val_loss: 613016272896.0000 - val_mae: 663128.0000\n",
            "Epoch 12/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 317297393664.0000 - mae: 509548.0000 - val_loss: 613001592832.0000 - val_mae: 663117.1250\n",
            "Epoch 13/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 343592108032.0000 - mae: 510520.8750 - val_loss: 612983963648.0000 - val_mae: 663104.1250\n",
            "Epoch 14/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 303750873088.0000 - mae: 501742.6562 - val_loss: 612964630528.0000 - val_mae: 663089.5000\n",
            "Epoch 15/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 359574536192.0000 - mae: 533385.5625 - val_loss: 612939268096.0000 - val_mae: 663070.9375\n",
            "Epoch 16/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 354522759168.0000 - mae: 525216.4375 - val_loss: 612911022080.0000 - val_mae: 663050.2500\n",
            "Epoch 17/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 341736226816.0000 - mae: 514155.9688 - val_loss: 612879302656.0000 - val_mae: 663026.6250\n",
            "Epoch 18/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 366952775680.0000 - mae: 540792.9375 - val_loss: 612842471424.0000 - val_mae: 662999.5000\n",
            "Epoch 19/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 394502012928.0000 - mae: 552583.0000 - val_loss: 612801118208.0000 - val_mae: 662969.5000\n",
            "Epoch 20/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 290104377344.0000 - mae: 491770.5625 - val_loss: 612757405696.0000 - val_mae: 662936.9375\n",
            "Epoch 21/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 325909741568.0000 - mae: 518330.3750 - val_loss: 612705304576.0000 - val_mae: 662898.8750\n",
            "Epoch 22/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 294611058688.0000 - mae: 480529.2500 - val_loss: 612649271296.0000 - val_mae: 662857.8125\n",
            "Epoch 23/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 354182135808.0000 - mae: 535357.1250 - val_loss: 612585308160.0000 - val_mae: 662811.3750\n",
            "Epoch 24/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 310310731776.0000 - mae: 509877.3438 - val_loss: 612520230912.0000 - val_mae: 662763.3750\n",
            "Epoch 25/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 342693216256.0000 - mae: 529445.7500 - val_loss: 612442832896.0000 - val_mae: 662707.6875\n",
            "Epoch 26/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 312148262912.0000 - mae: 507291.9688 - val_loss: 612368777216.0000 - val_mae: 662652.7500\n",
            "Epoch 27/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 319747325952.0000 - mae: 511539.3125 - val_loss: 612278665216.0000 - val_mae: 662587.6250\n",
            "Epoch 28/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 299113742336.0000 - mae: 489993.1875 - val_loss: 612186456064.0000 - val_mae: 662520.6250\n",
            "Epoch 29/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 337382866944.0000 - mae: 519618.1250 - val_loss: 612084416512.0000 - val_mae: 662446.2500\n",
            "Epoch 30/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 307138854912.0000 - mae: 500964.7812 - val_loss: 611980017664.0000 - val_mae: 662370.2500\n",
            "Epoch 31/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 335166013440.0000 - mae: 507282.1562 - val_loss: 611864674304.0000 - val_mae: 662286.2500\n",
            "Epoch 32/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 281823969280.0000 - mae: 486149.1250 - val_loss: 611750445056.0000 - val_mae: 662201.9375\n",
            "Epoch 33/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 297345253376.0000 - mae: 498911.0938 - val_loss: 611622322176.0000 - val_mae: 662108.0000\n",
            "Epoch 34/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 314492452864.0000 - mae: 514056.7500 - val_loss: 611489021952.0000 - val_mae: 662011.2500\n",
            "Epoch 35/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 312617730048.0000 - mae: 510048.1250 - val_loss: 611346808832.0000 - val_mae: 661907.7500\n",
            "Epoch 36/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 315555971072.0000 - mae: 510419.5000 - val_loss: 611191488512.0000 - val_mae: 661796.0000\n",
            "Epoch 37/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 276551630848.0000 - mae: 484382.5938 - val_loss: 611039444992.0000 - val_mae: 661683.4375\n",
            "Epoch 38/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 362477092864.0000 - mae: 527124.6250 - val_loss: 610860269568.0000 - val_mae: 661555.2500\n",
            "Epoch 39/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 324412342272.0000 - mae: 501010.7188 - val_loss: 610684436480.0000 - val_mae: 661428.0000\n",
            "Epoch 40/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 330020225024.0000 - mae: 532378.5000 - val_loss: 610507423744.0000 - val_mae: 661297.2500\n",
            "Epoch 41/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 337625513984.0000 - mae: 525001.8125 - val_loss: 610316845056.0000 - val_mae: 661158.0000\n",
            "Epoch 42/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 320459538432.0000 - mae: 516182.4375 - val_loss: 610106474496.0000 - val_mae: 661006.3750\n",
            "Epoch 43/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 312670355456.0000 - mae: 517051.9688 - val_loss: 609902657536.0000 - val_mae: 660857.0000\n",
            "Epoch 44/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 363963121664.0000 - mae: 521795.6875 - val_loss: 609671184384.0000 - val_mae: 660689.6250\n",
            "Epoch 45/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 326790905856.0000 - mae: 518183.7500 - val_loss: 609443577856.0000 - val_mae: 660525.0000\n",
            "Epoch 46/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 330176397312.0000 - mae: 520543.1875 - val_loss: 609205878784.0000 - val_mae: 660352.2500\n",
            "Epoch 47/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 318366449664.0000 - mae: 506423.0312 - val_loss: 608953237504.0000 - val_mae: 660169.6250\n",
            "Epoch 48/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 278657335296.0000 - mae: 487296.5000 - val_loss: 608719732736.0000 - val_mae: 659995.0000\n",
            "Epoch 49/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 352283328512.0000 - mae: 520051.5000 - val_loss: 608427835392.0000 - val_mae: 659785.1875\n",
            "Epoch 50/50\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 374249816064.0000 - mae: 517686.4375 - val_loss: 608145506304.0000 - val_mae: 659581.0000\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
            "Generation 1: Best Fitness = 13147.9736 | Chromosome = [6, 8, 0.32277351909048557, 0.6625993023119835, 2.5]\n",
            "Generation 2: Best Fitness = 13890.3887 | Chromosome = [7, 8, 0.32277351909048557, 0.6625993023119835, 2.5]\n",
            "Generation 3: Best Fitness = 14595.3096 | Chromosome = [7, 8, 0.8491080163389498, 0.6625993023119835, 3]\n",
            "Generation 4: Best Fitness = 14641.5928 | Chromosome = [7, 8, 0.9299601379596545, 0.6625993023119835, 3]\n",
            "Generation 5: Best Fitness = 14687.9463 | Chromosome = [7, 8, 0.8491080163389498, 0.9324837027185277, 3]\n",
            "Generation 6: Best Fitness = 14687.9473 | Chromosome = [7, 8, 0.8491080163389498, 0.9324837027185277, 3]\n",
            "Generation 7: Best Fitness = 14687.9473 | Chromosome = [7, 8, 0.8491080163389498, 0.9324837027185277, 3]\n",
            "Generation 8: Best Fitness = 14687.9473 | Chromosome = [7, 8, 0.8491080163389498, 0.9324837027185277, 3]\n",
            "Generation 9: Best Fitness = 14687.9463 | Chromosome = [7, 8, 0.8491080163389498, 0.9324837027185277, 3]\n",
            "Generation 10: Best Fitness = 14771.4873 | Chromosome = [7, 8, 0.9950406498121774, 0.9324837027185277, 3]\n",
            "Generation 11: Best Fitness = 14771.4873 | Chromosome = [7, 8, 0.9950406498121774, 0.9324837027185277, 3]\n",
            "Generation 12: Best Fitness = 14791.4580 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 13: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 14: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 15: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 16: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 17: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 18: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 19: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 20: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 21: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 22: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 23: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 24: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 25: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 26: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 27: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 28: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 29: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 30: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 31: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 32: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 33: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 34: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 35: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 36: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 37: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 38: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 39: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 40: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 41: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 42: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 43: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 44: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 45: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 46: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 47: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 48: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 49: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n",
            "Generation 50: Best Fitness = 14791.4590 | Chromosome = [7, 8, 0.9950406498121774, 0.9906644264155229, 3]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# 1. Load data from CSV\n",
        "data = pd.read_csv('/content/sample_data/house_price_norm.csv')  # Replace with your file\n",
        "X = data.drop(columns=['price']).values  # Features\n",
        "y = data['price'].values  # Target (continuous values)\n",
        "\n",
        "# 2. Split data into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Standardize features (critical for regression)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 4. Build ANN model for regression\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)  # No activation for regression\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# 5. Train the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                   epochs=50,\n",
        "                   batch_size=8,\n",
        "                   validation_split=0.2,\n",
        "                   verbose=1)\n",
        "\n",
        "# 6. Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ----- Prespecified Lists for Genes -----\n",
        "gene1_options = [2, 3, 4, 5, 6, 7]      # Gene 1: categorical\n",
        "gene2_options = [1, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 4.25, 8 ]       # Gene 2: categorical\n",
        "gene3_range = (0.0, 1.0)              # Gene 3: real\n",
        "gene4_range = (0.0, 1.0)              # Gene 4: real\n",
        "gene5_options = [1, 1.5, 2, 2.5, 3]        # Gene 5: categorical\n",
        "\n",
        "chromosome_length = 5\n",
        "population_size = 20\n",
        "generations = 50\n",
        "mutation_rate = 0.1\n",
        "elite_size = 2\n",
        "\n",
        "\n",
        "# ----- Gene Creation -----\n",
        "\n",
        "def create_gene(index):\n",
        "    if index == 0:\n",
        "        return random.choice(gene1_options)\n",
        "    elif index == 1:\n",
        "        return random.choice(gene2_options)\n",
        "    elif index == 2:\n",
        "        return np.random.uniform(*gene3_range)\n",
        "    elif index == 3:\n",
        "        return np.random.uniform(*gene4_range)\n",
        "    elif index == 4:\n",
        "        return random.choice(gene5_options)\n",
        "\n",
        "\n",
        "def create_chromosome():\n",
        "    return [create_gene(i) for i in range(chromosome_length)]\n",
        "\n",
        "\n",
        "def create_population():\n",
        "    return [create_chromosome() for _ in range(population_size)]\n",
        "\n",
        "\n",
        "# ----- Fitness Evaluation -----\n",
        "\n",
        "def evaluate_fitness(population):\n",
        "    inputs = np.array(population)\n",
        "    fitness_values = model.predict(inputs, verbose=0).flatten()\n",
        "    return fitness_values\n",
        "\n",
        "\n",
        "# ----- Selection, Crossover, Mutation -----\n",
        "\n",
        "def select_mating_pool(population, fitness, num_parents):\n",
        "    parents = [x for _, x in sorted(zip(fitness, population), reverse=True)]\n",
        "    return parents[:num_parents]\n",
        "\n",
        "\n",
        "def crossover(parent1, parent2):\n",
        "    point = random.randint(1, chromosome_length - 1)\n",
        "    child = parent1[:point] + parent2[point:]\n",
        "    return child\n",
        "\n",
        "\n",
        "def mutate(chromosome):\n",
        "    for i in range(chromosome_length):\n",
        "        if np.random.rand() < mutation_rate:\n",
        "            chromosome[i] = create_gene(i)\n",
        "    return chromosome\n",
        "\n",
        "\n",
        "def next_generation(current_pop, fitness):\n",
        "    new_population = []\n",
        "\n",
        "    # Elitism\n",
        "    elites = select_mating_pool(current_pop, fitness, elite_size)\n",
        "    new_population.extend(elites)\n",
        "\n",
        "    # Crossover and mutation\n",
        "    while len(new_population) < population_size:\n",
        "        parent1, parent2 = random.choices(elites, k=2)\n",
        "        child = crossover(parent1, parent2)\n",
        "        child = mutate(child)\n",
        "        new_population.append(child)\n",
        "\n",
        "    return new_population\n",
        "\n",
        "\n",
        "# ----- Main GA Loop -----\n",
        "\n",
        "population = create_population()\n",
        "\n",
        "for gen in range(generations):\n",
        "    fitness = evaluate_fitness(population)\n",
        "    best_idx = np.argmax(fitness)\n",
        "    best_fitness = fitness[best_idx]\n",
        "    best_chromosome = population[best_idx]\n",
        "    print(f\"Generation {gen+1}: Best Fitness = {best_fitness:.4f} | Chromosome = {best_chromosome}\")\n",
        "    population = next_generation(population, fitness)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}